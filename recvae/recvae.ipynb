{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import argparse\n",
    "from copy import deepcopy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import bottleneck as bn\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='RecVAE for Sequential Recommendation')\n",
    "\n",
    "parser.add_argument('--data_dir', type=str, default='../data/train/', help='Movielens train dataset path')\n",
    "parser.add_argument('--min_items_per_user', type=int, default=5)\n",
    "parser.add_argument('--min_users_per_item', type=int, default=0)\n",
    "parser.add_argument('--heldout_users', type=int, default=3000)\n",
    "parser.add_argument('--seed', type=int, default=42, help='random seed')\n",
    "parser.add_argument('--cuda', action='store_true', help='use CUDA')\n",
    "\n",
    "parser.add_argument('--hidden_dim', type=int, default=600)\n",
    "parser.add_argument('--latent_dim', type=int, default=300)\n",
    "parser.add_argument('--batch_size', type=int, default=64)\n",
    "parser.add_argument('--beta', type=float, default=0.1)\n",
    "parser.add_argument('--gamma', type=float, default=0.005)\n",
    "parser.add_argument('--lr', type=float, default=1e-4)\n",
    "parser.add_argument('--weight_decay', type=float, default=0)\n",
    "parser.add_argument('--scheduler', type=str, default='None') \n",
    "parser.add_argument('--dropout_rate', type=float, default=0.5)\n",
    "parser.add_argument('--n_epochs', type=int, default=120)\n",
    "parser.add_argument('--n_enc_epochs', type=int, default=3)\n",
    "parser.add_argument('--n_dec_epochs', type=int, default=1)\n",
    "parser.add_argument('--not_alternating', type=bool, default=False)\n",
    "\n",
    "exp_idx = 6\n",
    "parser.add_argument('--save', type=str, default=f'./ckpts/model_exp{exp_idx}.pt',\n",
    "                    help='path to save the final model')\n",
    "\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WandB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# login to WandB\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize WandB\n",
    "run = wandb.init(entity=\"new-recs\", project=\"movierec\", tags=[\"RecVAE\"], group=\"RecVAE_watchstep\", config=args)\n",
    "wandb.run.name = f\"RecVAE_watchstep_exp{exp_idx}\"\n",
    "run.save()\n",
    "print(wandb.run.name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `heldout_users` : select 3000 users as heldout user, 3000 users as validation users, and the rest of the users for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "if torch.cuda.is_available():\n",
    "  torch.cuda.manual_seed(args.seed)\n",
    "  args.cuda = True\n",
    "  \n",
    "device = torch.device('cuda:0' if args.cuda else 'cpu')\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = args.data_dir\n",
    "min_uc = args.min_items_per_user\n",
    "min_sc = args.min_users_per_item\n",
    "n_heldout_users = args.heldout_users "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/dawenl/vae_cf\n",
    "# https://github.com/ilya-shenbin/RecVAE \n",
    "\n",
    "# Pandas version : 2.0.2\n",
    "def get_count(tp, id):\n",
    "  playcount_groupbyid = tp[[id]].groupby(id)\n",
    "  count = playcount_groupbyid.size()\n",
    "   \n",
    "  return count\n",
    "\n",
    "# Only keep items that are clicked on by at least 5 users \n",
    "def filter_triplets(tp, min_uc=min_uc, min_sc=min_sc):\n",
    "  # Only keep the triplets for items which were clicked on by at least min_sc users.\n",
    "  if min_sc > 0:\n",
    "    item_count = get_count(tp, 'item')\n",
    "    tp = tp[tp['item'].isin(item_count.index[item_count >= min_sc])]\n",
    "    \n",
    "  # Only keep the triplets for users who clicked on at least min_uc items\n",
    "  # After, some of the items will have less than min_uc users, but should only be a small proportion\n",
    "  if min_uc > 0:\n",
    "    user_count = get_count(tp, 'user')\n",
    "    tp = tp[tp['user'].isin(user_count.index[user_count >= min_uc])]\n",
    "  \n",
    "  \n",
    "  # Update both usercount and itemcount after filtering\n",
    "  user_count, item_count = get_count(tp, 'user'), get_count(tp, 'item')\n",
    "  return tp, user_count, item_count"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(os.path.join(data_dir, 'train_ratings.csv'), header=0)\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data, user_activity, item_popularity = filter_triplets(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity = 1. * raw_data.shape[0] / (user_activity.shape[0] * item_popularity.shape[0])\n",
    "\n",
    "print('After filtering')\n",
    "print('============================================')\n",
    "print(f'{raw_data.shape[0]} events from {user_activity.shape[0]} users & {item_popularity.shape[0]} movies')\n",
    "print(f'sparsity: {sparsity*100:.3f}%')\n",
    "\n",
    "# 원본 데이터셋과 똑같은 결과 (이미 5번 이상의 리뷰가 있는 user들로만 이루어진 데이터)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_activity.head() # user별 리뷰수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_popularity.head() # item별 리뷰수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_uid = user_activity.index\n",
    "unique_uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle User Indices\n",
    "unique_uid = user_activity.index\n",
    "\n",
    "unique_uid_before_shuffling = user_activity.index\n",
    "\n",
    "print('Before shuffling')\n",
    "print('================')\n",
    "print(unique_uid)\n",
    "\n",
    "idx_perm = np.random.permutation(unique_uid.size)\n",
    "unique_uid = unique_uid[idx_perm]\n",
    "print('\\nAfter shuffling')\n",
    "print('================')\n",
    "print(unique_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/validation/test users\n",
    "n_users = unique_uid.size\n",
    "n_heldout_users = args.heldout_users # 10000\n",
    "\n",
    "tr_users = unique_uid[:(n_users - n_heldout_users*2)]\n",
    "vd_users = unique_uid[(n_users - n_heldout_users*2):(n_users - n_heldout_users)]\n",
    "te_users = unique_uid[(n_users - n_heldout_users):]\n",
    "\n",
    "print(f'# of all users: {n_users}')\n",
    "print(f'# of train users: {len(tr_users)}')\n",
    "print(f'# of validation users: {len(vd_users)}')\n",
    "print(f'# of test users: {len(te_users)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_proportion(data, test_prop=0.2):\n",
    "  data_grouped_by_user = data.groupby('user')\n",
    "  tr_list, te_list = [], []\n",
    "  \n",
    "  np.random.seed(args.seed)\n",
    "  \n",
    "  for i, (_, group) in enumerate(data_grouped_by_user):\n",
    "    n_items_u = len(group)\n",
    "    \n",
    "    if n_items_u >= 5:\n",
    "      idx = np.zeros(n_items_u, dtype='bool')\n",
    "      idx[np.random.choice(n_items_u, size=int(test_prop*n_items_u), replace=False).astype('int64')] = True\n",
    "      \n",
    "      tr_list.append(group[np.logical_not(idx)])\n",
    "      te_list.append(group[idx])\n",
    "      \n",
    "    else:\n",
    "      tr_list.append(group)\n",
    "      \n",
    "    if i % 1000 == 0:\n",
    "      print(f'{i} users sampled')\n",
    "      sys.stdout.flush()\n",
    "      \n",
    "  data_tr = pd.concat(tr_list)\n",
    "  data_te = pd.concat(te_list)\n",
    "  \n",
    "  return data_tr, data_te\n",
    "\n",
    "def numerize(tp, profile2id, show2id):\n",
    "  uid = tp['user'].apply(lambda x: profile2id[x])\n",
    "  sid = tp['item'].apply(lambda x: show2id[x])\n",
    "  \n",
    "  return pd.DataFrame(data={'uid': uid, 'sid': sid}, columns=['uid', 'sid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data는 전체 데이터 모두 사용\n",
    "train_plays = raw_data.loc[raw_data['user'].isin(tr_users)]\n",
    "\n",
    "unique_sid = pd.unique(train_plays['item'])\n",
    "\n",
    "show2id = dict((sid, i) for (i, sid) in enumerate(unique_sid))\n",
    "profile2id = dict((pid, i) for (i, pid) in enumerate(unique_uid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(data_dir):\n",
    "  os.makedirs(data_dir)\n",
    "\n",
    "with open(os.path.join(data_dir, 'unique_sid.txt'), 'w') as f:\n",
    "  for sid in unique_sid:\n",
    "    f.write(f'{sid}\\n')\n",
    "    \n",
    "with open(os.path.join(data_dir, 'unique_uid.txt'), 'w') as f:\n",
    "  for uid in unique_uid:\n",
    "    f.write(f'{uid}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation / test data는 input인 tr 데이터와 정답 확인하기 위한 te 데이터로 분리\n",
    "vad_plays = raw_data.loc[raw_data['user'].isin(vd_users)]\n",
    "vad_plays = vad_plays.loc[vad_plays['item'].isin(unique_sid)]\n",
    "\n",
    "vad_plays_tr, vad_plays_te = split_train_test_proportion(vad_plays)\n",
    "\n",
    "test_plays = raw_data.loc[raw_data['user'].isin(te_users)]\n",
    "test_plays = test_plays.loc[test_plays['item'].isin(unique_sid)]\n",
    "\n",
    "test_plays_tr, test_plays_te = split_train_test_proportion(test_plays)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save data into (user_index, item_index) format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = numerize(train_plays, profile2id, show2id)\n",
    "train_data.to_csv(os.path.join(data_dir, 'train.csv'), index=False)\n",
    "\n",
    "vad_data_tr = numerize(vad_plays_tr, profile2id, show2id)\n",
    "vad_data_tr.to_csv(os.path.join(data_dir, 'validation_tr.csv'), index=False)\n",
    "\n",
    "vad_data_te = numerize(vad_plays_te, profile2id, show2id)\n",
    "vad_data_te.to_csv(os.path.join(data_dir, 'validation_te.csv'), index=False)\n",
    "\n",
    "test_data_tr = numerize(test_plays_tr, profile2id, show2id)\n",
    "test_data_tr.to_csv(os.path.join(data_dir, 'test_tr.csv'), index=False)\n",
    "\n",
    "test_data_te = numerize(test_plays_te, profile2id, show2id)\n",
    "test_data_te.to_csv(os.path.join(data_dir, 'test_te.csv'), index=False)\n",
    "\n",
    "# uid sorting for submission (before shuffling )\n",
    "profile2id = dict((pid, i) for (i, pid) in enumerate(unique_uid_before_shuffling))\n",
    "inference_data = numerize(raw_data, profile2id, show2id)\n",
    "inference_data.to_csv(os.path.join(data_dir, 'inference.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vad_data_tr.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_tr.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_data.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "  '''\n",
    "  Load Movielens dataset for RecVAE\n",
    "  ''' \n",
    "  def __init__(self, data_dir):\n",
    "    self.data_dir = data_dir\n",
    "    assert os.path.exists(data_dir), \"DATA NOT EXIT\"\n",
    "    \n",
    "    self.n_items = self.load_n_items()\n",
    "  \n",
    "  def load_data(self, data_type='train'):\n",
    "    if data_type == 'train':\n",
    "      return self._load_train_data(data_type)\n",
    "    elif data_type == 'validation':\n",
    "      return self._load_tr_te_data(data_type)\n",
    "    elif data_type == 'test':\n",
    "      return self._load_tr_te_data(data_type)\n",
    "    elif data_type == 'inference':\n",
    "      return self._load_train_data(data_type)\n",
    "    else:\n",
    "      raise ValueError('datatype should be in [train, validation, test, inference]')\n",
    "  \n",
    "  def load_items(self):\n",
    "    unique_sid = np.loadtxt(os.path.join(self.data_dir, 'unique_sid.txt'))\n",
    "    return unique_sid\n",
    "  \n",
    "  def load_n_items(self):\n",
    "    unique_sid = []\n",
    "    with open(os.path.join(self.data_dir, 'unique_sid.txt'), 'r') as f:\n",
    "      for line in f:\n",
    "        unique_sid.append(line.strip())\n",
    "        \n",
    "    n_items = len(unique_sid)\n",
    "    return n_items\n",
    "  \n",
    "  def load_n_users(self):\n",
    "    unique_uid = []\n",
    "    with open(os.path.join(self.data_dir, 'unique_uid.txt'), 'r') as f:\n",
    "      for line in f:\n",
    "        unique_uid.append(line.strip())\n",
    "    \n",
    "    n_users = len(unique_uid)\n",
    "    return n_users\n",
    "  \n",
    "  def _load_train_data(self, data_type='train'):\n",
    "    path = os.path.join(self.data_dir, '{}.csv'.format(data_type))\n",
    "    \n",
    "    tp = pd.read_csv(path)\n",
    "    n_users = tp['uid'].max() + 1\n",
    "    \n",
    "    rows, cols = tp['uid'], tp['sid']\n",
    "    data = sparse.csr_matrix((np.ones_like(rows),\n",
    "                             (rows, cols)), dtype='float64',\n",
    "                             shape=(n_users, self.n_items))\n",
    "    \n",
    "    return data\n",
    "  \n",
    "  def _load_tr_te_data(self, data_type='test'):\n",
    "    tr_path = os.path.join(self.data_dir, '{}_tr.csv'.format(data_type))\n",
    "    te_path = os.path.join(self.data_dir, '{}_te.csv'.format(data_type))\n",
    "\n",
    "    tp_tr = pd.read_csv(tr_path)\n",
    "    tp_te = pd.read_csv(te_path)\n",
    "\n",
    "    start_idx = min(tp_tr['uid'].min(), tp_te['uid'].min())\n",
    "    end_idx = max(tp_tr['uid'].max(), tp_te['uid'].max())\n",
    "\n",
    "    rows_tr, cols_tr = tp_tr['uid'] - start_idx, tp_tr['sid']\n",
    "    rows_te, cols_te = tp_te['uid'] - start_idx, tp_te['sid']\n",
    "\n",
    "    data_tr = sparse.csr_matrix((np.ones_like(rows_tr),\n",
    "                                (rows_tr, cols_tr)), dtype='float64', shape=(end_idx - start_idx + 1, self.n_items))\n",
    "    data_te = sparse.csr_matrix((np.ones_like(rows_te),\n",
    "                                (rows_te, cols_te)), dtype='float64', shape=(end_idx - start_idx + 1, self.n_items))\n",
    "    \n",
    "    return data_tr, data_te"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://recbole.io/docs/_images/recvae.png\" width='400'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swish(x):\n",
    "  return x.mul(torch.sigmoid(x))\n",
    "\n",
    "def log_norm_pdf(x, mu, logvar):\n",
    "  return -0.5*(logvar + np.log(2 * np.pi) + (x - mu).pow(2) / logvar.exp())\n",
    "\n",
    "class CompositePrior(nn.Module):\n",
    "  def __init__(self, hidden_dim, latent_dim, input_dim, mixture_weights=[3/20, 3/4, 1/10]):\n",
    "    super(CompositePrior, self).__init__()\n",
    "    \n",
    "    self.mixture_weights = mixture_weights\n",
    "    \n",
    "    self.mu_prior = nn.Parameter(torch.Tensor(1, latent_dim), requires_grad=False)\n",
    "    self.mu_prior.data.fill_(0)\n",
    "    \n",
    "    self.logvar_prior = nn.Parameter(torch.Tensor(1, latent_dim), requires_grad=False)\n",
    "    self.logvar_prior.data.fill_(0)\n",
    "    \n",
    "    self.logvar_uniform_prior = nn.Parameter(torch.Tensor(1, latent_dim), requires_grad=False)\n",
    "    self.logvar_uniform_prior.data.fill_(10)\n",
    "    \n",
    "    self.encoder_old = Encoder(hidden_dim, latent_dim, input_dim)\n",
    "    self.encoder_old.requires_grad_(False)\n",
    "    \n",
    "  def forward(self, x, z):\n",
    "    post_mu, post_logvar = self.encoder_old(x, 0)\n",
    "    \n",
    "    # encoder의 output과 이전 epoch의 파라미터를 지정한 encoder (as a pior)간의 KL Divergence\n",
    "    stnd_prior = log_norm_pdf(z, self.mu_prior, self.logvar_prior)\n",
    "    post_prior = log_norm_pdf(z, post_mu, post_logvar)\n",
    "    unif_prior = log_norm_pdf(z, self.mu_prior, self.logvar_uniform_prior)\n",
    "    \n",
    "    gaussians = [stnd_prior, post_prior, unif_prior]\n",
    "    gaussians = [g.add(np.log(w)) for g, w in zip(gaussians, self.mixture_weights)]\n",
    "    \n",
    "    density_per_gaussian = torch.stack(gaussians, dim=-1)\n",
    "    \n",
    "    return torch.logsumexp(density_per_gaussian, dim=-1)\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "  def __init__(self, hidden_dim, latent_dim, input_dim, eps=1e-1):\n",
    "    super(Encoder, self).__init__()\n",
    "    \n",
    "    self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "    self.ln1 = nn.LayerNorm(hidden_dim, eps=eps)\n",
    "    self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "    self.ln2 = nn.LayerNorm(hidden_dim, eps=eps)\n",
    "    self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n",
    "    self.ln3 = nn.LayerNorm(hidden_dim, eps=eps)\n",
    "    self.fc4 = nn.Linear(hidden_dim, hidden_dim)\n",
    "    self.ln4 = nn.LayerNorm(hidden_dim, eps=eps)\n",
    "    self.fc5 = nn.Linear(hidden_dim, hidden_dim)\n",
    "    self.ln5 = nn.LayerNorm(hidden_dim, eps=eps)\n",
    "    self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n",
    "    self.fc_logvar = nn.Linear(hidden_dim, latent_dim)\n",
    "    \n",
    "  def forward(self, x, dropout_rate):\n",
    "    norm = x.pow(2).sum(dim=-1).sqrt()\n",
    "    x = x / norm[:, None]\n",
    "    \n",
    "    x = F.dropout(x, p=dropout_rate, training=self.training)\n",
    "    \n",
    "    h1 = self.ln1(swish(self.fc1(x)))\n",
    "    h2 = self.ln2(swish(self.fc2(h1) + h1))\n",
    "    h3 = self.ln3(swish(self.fc3(h2) + h1 + h2))\n",
    "    h4 = self.ln4(swish(self.fc4(h3) + h1 + h2 + h3))\n",
    "    h5 = self.ln5(swish(self.fc5(h4) + h1 + h2 + h3 + h4))\n",
    "    \n",
    "    return self.fc_mu(h5), self.fc_logvar(h5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecVAE(nn.Module):\n",
    "  def __init__(self, hidden_dim, latent_dim, input_dim):\n",
    "    super(RecVAE, self).__init__()\n",
    "    \n",
    "    self.encoder = Encoder(hidden_dim, latent_dim, input_dim)\n",
    "    self.prior = CompositePrior(hidden_dim, latent_dim, input_dim)\n",
    "    self.decoder = nn.Linear(latent_dim, input_dim)\n",
    "    \n",
    "  def reparameterize(self, mu, logvar):\n",
    "    if self.training:\n",
    "      std = torch.exp(0.5*logvar)\n",
    "      eps = torch.randn_like(std)\n",
    "      return eps.mul(std).add_(mu)\n",
    "    else:\n",
    "      return mu\n",
    "  \n",
    "  def forward(self, user_ratings, beta=None, gamma=1, dropout_rate=0.5, calculate_loss=True):\n",
    "    mu, logvar = self.encoder(user_ratings, dropout_rate=dropout_rate)\n",
    "    z = self.reparameterize(mu, logvar)\n",
    "    x_pred = self.decoder(z)\n",
    "    \n",
    "    if calculate_loss:\n",
    "      if gamma:\n",
    "        norm = user_ratings.sum(dim=-1)\n",
    "        kl_weight = gamma*norm\n",
    "      elif beta:\n",
    "        kl_weight = beta\n",
    "      \n",
    "      mll = (F.log_softmax(x_pred, dim=-1) * user_ratings).sum(dim=-1).mean()\n",
    "      kld = (log_norm_pdf(z, mu, logvar) - self.prior(user_ratings, z)).sum(dim=-1).mul(kl_weight).mean()\n",
    "      negative_elbo = -(mll - kld)\n",
    "      \n",
    "      return (mll, kld), negative_elbo\n",
    "    \n",
    "    else:\n",
    "      return x_pred\n",
    "  \n",
    "  def update_prior(self):\n",
    "    self.prior.encoder_old.load_state_dict(deepcopy(self.encoder.state_dict()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndcg(X_pred, heldout_batch, k=100):\n",
    "  '''\n",
    "  normalized discounted cumulative gain@k for binary relevance\n",
    "  ASSUMPTIONS: all the 0's in heldout_data indicate 0 relevance\n",
    "  '''\n",
    "  batch_users = X_pred.shape[0]\n",
    "  idx_topk_part = bn.argpartition(-X_pred, k, axis=1)\n",
    "  topk_part = X_pred[np.arange(batch_users)[:, np.newaxis],\n",
    "                     idx_topk_part[:, :k]]\n",
    "  idx_part = np.argsort(-topk_part, axis=1)\n",
    "  \n",
    "  idx_topk = idx_topk_part[np.arange(batch_users)[:, np.newaxis], idx_part]\n",
    "  \n",
    "  tp = 1. / np.log2(np.arange(2, k+2))\n",
    "  \n",
    "  DCG = (heldout_batch[np.arange(batch_users)[:, np.newaxis],\n",
    "                       idx_topk].toarray() * tp).sum(axis=1)\n",
    "  IDCG = np.array([(tp[:min(n, k)]).sum()\n",
    "                   for n in heldout_batch.getnnz(axis=1)])\n",
    "  return DCG / IDCG\n",
    "\n",
    "\n",
    "def recall(X_pred, heldout_batch, k=100):\n",
    "  batch_users = X_pred.shape[0]\n",
    "  \n",
    "  idx = bn.argpartition(-X_pred, k, axis=1)\n",
    "  X_pred_binary = np.zeros_like(X_pred, dtype=bool)\n",
    "  X_pred_binary[np.arange(batch_users)[:, np.newaxis], idx[:, :k]] = True\n",
    "  \n",
    "  X_true_binary = (heldout_batch > 0).toarray()\n",
    "  tmp = (np.logical_and(X_true_binary, X_pred_binary).sum(axis=1)).astype(np.float32)\n",
    "  \n",
    "  recall = tmp / np.minimum(k, X_true_binary.sum(axis=1))\n",
    "  \n",
    "  return recall"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(batch_size, device, data_in, data_out=None, shuffle=False, samples_perc_per_epoch=1):\n",
    "  assert 0 < samples_perc_per_epoch <= 1\n",
    "  \n",
    "  N = data_in.shape[0]\n",
    "  samples_per_epoch = int(N * samples_perc_per_epoch)\n",
    "  \n",
    "  if shuffle:\n",
    "    idx_list = np.arange(N)\n",
    "    np.random.shuffle(idx_list)\n",
    "    idx_list = idx_list[:samples_per_epoch]\n",
    "  else:\n",
    "    idx_list = np.arange(samples_per_epoch)\n",
    "  \n",
    "  for st_idx in range(0, samples_per_epoch, batch_size):\n",
    "    end_idx = min(st_idx + batch_size, samples_per_epoch)\n",
    "    idx = idx_list[st_idx:end_idx]\n",
    "    \n",
    "    yield Batch(device, idx, data_in, data_out)\n",
    "    \n",
    "class Batch:\n",
    "  def __init__(self, device, idx, data_in, data_out=None):\n",
    "    self._device = device\n",
    "    self._idx = idx\n",
    "    self._data_in = data_in\n",
    "    self._data_out = data_out\n",
    "    \n",
    "  def get_idx(self):\n",
    "    return self._idx\n",
    "  \n",
    "  def get_idx_to_dev(self):\n",
    "    return torch.LongTensor(self.get_idx()).to(self._device)\n",
    "  \n",
    "  def get_ratings(self, is_out=False):\n",
    "    data = self._data_out if is_out else self._data_in\n",
    "    return data[self._idx]\n",
    "  \n",
    "  def get_ratings_to_dev(self, is_out=False):\n",
    "    return torch.Tensor(\n",
    "      self.get_ratings(is_out).toarray()\n",
    "    ).to(self._device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, opts, sches, train_data, batch_size, n_epochs, beta, gamma, dropout_rate):\n",
    "  # training mode\n",
    "  model.train()\n",
    "  \n",
    "  for epoch in range(n_epochs):\n",
    "    for batch in generate(batch_size, device, data_in=train_data, shuffle=True):\n",
    "      ratings = batch.get_ratings_to_dev()\n",
    "      \n",
    "      for optimizer in opts:\n",
    "        optimizer.zero_grad()\n",
    "      \n",
    "      _, loss = model(ratings, beta, gamma, dropout_rate)\n",
    "      loss.backward()\n",
    "      \n",
    "      for optimizer in opts:\n",
    "        optimizer.step()\n",
    "        \n",
    "    # learning rate scheduling\n",
    "    for scheduler in sches:\n",
    "      scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_in, data_out, metrics, samples_perc_per_epoch=1, batch_size=500):\n",
    "  # evaluation mode\n",
    "  model.eval()\n",
    "  metrics = deepcopy(metrics)\n",
    "  \n",
    "  for m in metrics:\n",
    "    m['score'] = []\n",
    "    \n",
    "  for batch in generate(batch_size, \n",
    "                        device, \n",
    "                        data_in, \n",
    "                        data_out,\n",
    "                        samples_perc_per_epoch):\n",
    "    \n",
    "    items_in = batch.get_ratings_to_dev()\n",
    "    items_out = batch.get_ratings(is_out=True)\n",
    "    \n",
    "    items_pred = model(items_in, calculate_loss=False).cpu().detach().numpy()\n",
    "    \n",
    "    if not(data_in is data_out):\n",
    "      items_pred[batch.get_ratings().nonzero()] = -np.inf\n",
    "      \n",
    "    for m in metrics:\n",
    "      m['score'].append(m['metric'](items_pred, items_out, k=m['k']))\n",
    "      \n",
    "  \n",
    "  for m in metrics:\n",
    "    m['score'] = np.concatenate(m['score']).mean()\n",
    "    \n",
    "  return [x['score'] for x in metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "loader = DataLoader(args.data_dir)\n",
    "\n",
    "n_items = loader.load_n_items()\n",
    "n_users = loader.load_n_users()\n",
    "\n",
    "train_data = loader.load_data('train')\n",
    "vad_data_tr, vad_data_te = loader.load_data('validation')\n",
    "test_data_tr, test_data_te = loader.load_data('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kwargs = {\n",
    "  'hidden_dim': args.hidden_dim,\n",
    "  'latent_dim': args.latent_dim,\n",
    "  'input_dim': train_data.shape[1]\n",
    "}\n",
    "\n",
    "metrics = [{'metric': ndcg, 'k': 100}, {'metric': recall, 'k': 20}, {'metric': recall, 'k': 50}]\n",
    "\n",
    "best_ndcg = -np.inf\n",
    "train_scores, valid_scores = [], []\n",
    "\n",
    "model = RecVAE(**model_kwargs).to(device)\n",
    "model_best = RecVAE(**model_kwargs).to(device)\n",
    "\n",
    "learning_kwargs = {\n",
    "  'model': model,\n",
    "  'train_data': train_data,\n",
    "  'batch_size': args.batch_size,\n",
    "  'beta': args.beta,\n",
    "  'gamma': args.gamma\n",
    "}\n",
    "\n",
    "decoder_params = set(model.decoder.parameters())\n",
    "encoder_params = set(model.encoder.parameters())\n",
    "\n",
    "# https://pytorch.org/docs/stable/optim.html\n",
    "optimizer_encoder = optim.Adam(encoder_params, lr=args.lr, weight_decay=args.weight_decay)\n",
    "optimizer_decoder = optim.Adam(decoder_params, lr=args.lr, weight_decay=args.weight_decay)\n",
    "scheduler_encoder = optim.lr_scheduler.CosineAnnealingLR(optimizer_encoder, T_max=50, eta_min=0.0001)\n",
    "scheduler_decoder = optim.lr_scheduler.CosineAnnealingLR(optimizer_decoder, T_max=50, eta_min=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(args.n_epochs):\n",
    "  if args.not_alternating:\n",
    "    train(opts=[optimizer_encoder, optimizer_decoder], sches=[scheduler_encoder, scheduler_decoder], epochs=1, dropout_rate=args.dropout_rate, **learning_kwargs)\n",
    "  else:\n",
    "    train(opts=[optimizer_encoder], sches=[scheduler_encoder], n_epochs=args.n_enc_epochs, dropout_rate=args.dropout_rate, **learning_kwargs)\n",
    "    model.update_prior()\n",
    "    train(opts=[optimizer_decoder], sches=[scheduler_decoder], n_epochs=args.n_dec_epochs, dropout_rate=0, **learning_kwargs)\n",
    "  \n",
    "  train_scores.append(\n",
    "    evaluate(model, train_data, train_data, metrics, 0.01)[0]\n",
    "  )\n",
    "  \n",
    "  valid_scores.append(\n",
    "    evaluate(model, vad_data_tr, vad_data_te, metrics, 1)[0]\n",
    "  )\n",
    "  \n",
    "  if valid_scores[-1] > best_ndcg:\n",
    "    best_ndcg = valid_scores[-1]\n",
    "    model_best.load_state_dict(deepcopy(model.state_dict()))\n",
    "    with open(args.save, 'wb') as f:\n",
    "      torch.save(model, f)\n",
    "    \n",
    "  print(f'epoch {epoch} | valid ndcg@100: {valid_scores[-1]:.4f} | ' +\n",
    "        f'best valid: {best_ndcg:.4f} | train ndcg@100: {train_scores[-1]:.4f}')\n",
    "  \n",
    "  if (epoch % 10) == 0:\n",
    "    wandb.log({\"best valid\": best_ndcg, \"valid ndcg@100\": valid_scores[-1], \"train ndcg@100\": train_scores[-1]})\n",
    "\n",
    "# test data  \n",
    "test_metrics = [{'metric': ndcg, 'k': 100}, {'metric': recall, 'k': 20}, {'metric': recall, 'k': 50}]\n",
    "\n",
    "final_scores = evaluate(model_best, test_data_tr, test_data_te, test_metrics)\n",
    "\n",
    "for metric, score in zip(test_metrics, final_scores):\n",
    "  print(f\"{metric['metric'].__name__}@{metric['k']}:\\t{score:.4f}\")\n",
    "\n",
    "wandb.log({\"test ndcg@100\": final_scores[0], \"test recall@20\": final_scores[1], \"test recall@50\": final_scores[2]})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best saved model.\n",
    "with open(args.save, 'rb') as f:\n",
    "  model = torch.load(f)\n",
    "  \n",
    "loader = DataLoader(args.data_dir)\n",
    "\n",
    "# load inference data\n",
    "inference_data = loader.load_data('inference')\n",
    "\n",
    "n_items = loader.load_n_items() # train_data.shape[1]\n",
    "n_users = loader.load_n_users() # train_data.shape[0]\n",
    "\n",
    "print(f'# of items: {n_items}')\n",
    "print(f'# of users: {n_users}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, data_in, samples_perc_per_epoch=1, batch_size=500):\n",
    "  model.eval()\n",
    "  output = []\n",
    "  \n",
    "  with torch.no_grad():\n",
    "    for batch in generate(batch_size, \n",
    "                          device,\n",
    "                          data_in,\n",
    "                          samples_perc_per_epoch):\n",
    "      \n",
    "      ratings_in = batch.get_ratings_to_dev()\n",
    "      \n",
    "      ratings_pred = model(ratings_in, calculate_loss=False).detach().cpu().numpy()\n",
    "      \n",
    "      # remove watched items\n",
    "      ratings_pred[batch.get_ratings().nonzero()] = -np.inf\n",
    "      \n",
    "      n_users = ratings_pred.shape[0]\n",
    "      for i in range(n_users):\n",
    "        output.append(ratings_pred[i])\n",
    "        \n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_output = inference(model, inference_data)\n",
    "\n",
    "submission = []\n",
    "\n",
    "for idx in range(n_users):\n",
    "  # item descending order\n",
    "  sid_idx_preds_per_user = np.argsort(inference_output[idx])[::-1]\n",
    "  sid_preds = unique_sid[sid_idx_preds_per_user]\n",
    "  \n",
    "  tmp = []\n",
    "  for item in sid_preds:\n",
    "    if len(tmp) == 10:\n",
    "      break\n",
    "    tmp.append((unique_uid_before_shuffling[idx], item))\n",
    "  \n",
    "  submission.extend(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame(submission, columns=['user', 'item'])\n",
    "submission_df.to_csv(f'./submissions/recvae_submission_exp{exp_idx}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finish WandB run\n",
    "run.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
